%matplotlib inline


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt








pew_religion_salary = pd.read_csv("pew.csv")


pew_religion_salary


tidy_pew = pew_religion_salary.melt(id_vars = ["religion"], var_name = "income", value_name = "frequency")


tidy_pew


tidy_pew.columns


tidy_pew.dtypes


tidy_pew = tidy_pew.select_dtypes(include=["object"]).astype("category")

# tidy_pew.religion = tidy_pew.religion.astype("category")
# tidy_pew.income = tidy_pew.income.astype("category")


tidy_pew.dtypes





tb_research = pd.read_csv("tb.csv")


tb_research


tb_research.columns


tb_research.dtypes


tb_research[(tb_research.year == 1989) & (tb_research.iso2 == "AD")].values # values ​​in the entire row are missing


tb_research.describe().T # "count" gives the number of non-missing values


tidy_tb_research = tb_research.melt(id_vars = ["iso2", "year"], var_name = "gender_and_age", value_name = "frequency")


tidy_tb_research["gender"] = tidy_tb_research.gender_and_age.str.slice(0, 1)


tidy_tb_research["gender"].unique()


tidy_tb_research["age_group"] = tidy_tb_research.gender_and_age.str.slice(1)


tidy_tb_research["age_group"].unique()


new_tidy_tb_research = tidy_tb_research.drop(columns = "gender_and_age")


new_tidy_tb_research


new_tidy_tb_research.describe().T


new_tidy_tb_research_nona = new_tidy_tb_research.dropna()


new_tidy_tb_research_nona


new_tidy_tb_research_nona.frequency.mean()


new_tidy_tb_research_nona[new_tidy_tb_research_nona.iso2 == "ZM"].frequency.mean()


new_tidy_tb_research_nona.age_group.unique()


# function that changes column "age_group" in more readable form:
def process_age_group(age_group): 
    correct_age_titles = {"04": "0-4", "65": "65+", "u": "unknown"}
    if age_group in correct_age_titles:
        return correct_age_titles[age_group]
        
    return f"{age_group[:-2]}-{age_group[-2:]}"


process_age_group("2534")


# .apply(func) - applies the given function to each value in the column
new_tidy_tb_research_nona.age_group = new_tidy_tb_research_nona.age_group.apply(process_age_group)


new_tidy_tb_research_nona


total_deaths = new_tidy_tb_research_nona["frequency"].sum()
print(f"Total number of deaths cases: {int(total_deaths)}.")


country_frequency = new_tidy_tb_research_nona.groupby("iso2")["frequency"].sum()
country_with_max_deaths = country_frequency.idxmax()
country_max_deaths_count = country_frequency.max()
print(f"Country {country_with_max_deaths} has the most deaths cases: {int(country_max_deaths_count)}")


age_group_order = ["0-4", "5-14", "0-14", "15-24", "25-34", "35-44", "45-54", "55-64", "65+", "unknown"]
new_tidy_tb_research_nona["age_group"] = pd.Categorical(new_tidy_tb_research_nona["age_group"], categories=age_group_order)
age_group_frequency = new_tidy_tb_research_nona.groupby("age_group", observed=True)["frequency"].sum()
age_group_max_deaths = age_group_frequency.idxmax()
age_group_max_deaths_count = age_group_frequency.max()
print(f"The age group {age_group_max_deaths} has the most deaths cases: {int(age_group_max_deaths_count)}.")

plt.figure(figsize=(8, 10))
plt.bar(age_group_frequency.index, age_group_frequency.values)
plt.xlabel("age group")
plt.ylabel("frequency of deaths")
plt.show()


year_frequency = new_tidy_tb_research_nona.groupby("year")["frequency"].sum()
year_with_max_deaths = year_frequency.idxmax()
year_with_max_deaths_count = year_frequency.max()
print(f"In {year_with_max_deaths} there were the most deaths cases: {int(year_with_max_deaths_count)}.")

plt.figure(figsize=(10, 5))
plt.bar(year_frequency.index, year_frequency.values)
plt.xlabel("year")
plt.ylabel("frequency of deaths")
plt.show()


gender_frequency = new_tidy_tb_research_nona.groupby("gender", observed=True)["frequency"].sum()
gender_with_more_deaths = gender_frequency.idxmax()
gender_with_less_deaths = gender_frequency.idxmin()
gender_with_more_deaths_count = gender_frequency.max()
gender_with_less_deaths_count = gender_frequency.min()
print(f"Gender '{gender_with_more_deaths}' has more death cases: {int(gender_with_more_deaths_count)}, "
      f"than gender '{gender_with_less_deaths}' with {gender_with_less_deaths_count} death cases.")


fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))
ax1.pie(gender_frequency, labels=gender_frequency.index, autopct="%1.1f%%", colors = ["green", "red"], startangle=140)
ax1.set_title("Death cases by gender")
ax2.pie(new_tidy_tb_research_nona.gender.value_counts(), labels=gender_frequency.index, autopct="%1.1f%%", colors = ["green", "red"], startangle=140)
ax2.set_title("Number of males / females in df")
plt.show()


new_tidy_tb_research_nona.gender = new_tidy_tb_research_nona.gender.astype("category")
new_tidy_tb_research_nona.age_group = new_tidy_tb_research_nona.age_group.astype("category")


new_tidy_tb_research_nona.dtypes


new_tidy_tb_research_nona = new_tidy_tb_research_nona[["iso2", "year", "gender", "age_group", "frequency"]]


new_tidy_tb_research_nona


new_tidy_tb_research_nona.frequency = new_tidy_tb_research_nona.frequency.astype(int)


# sort entries by iso2, if there are more than one entries with same country then sort by year:
sorted_tidy_tb_research = new_tidy_tb_research_nona.sort_values(["iso2", "year"])


sorted_tidy_tb_research = sorted_tidy_tb_research.reset_index(drop=True)


sorted_tidy_tb_research


sorted_tidy_tb_research.to_csv("tidy_tb_research.csv", index = None)





weather_df = pd.read_csv("weather.csv")


weather_df


weather_df = weather_df.melt(id_vars=["id", "year", "month", "element"], var_name="day")


weather_df.day.unique()


weather_df.day = weather_df.day.str.slice(1) # crop first char in day: d1 -> 1


weather_df.day = weather_df.day.astype(int) # change day's type from char to int 


weather_tidy = weather_df.dropna()


data = ["id", "year", "month", "day"]
weather_tidy = weather_tidy.pivot_table(index = data, columns = "element", values = "value")


weather_tidy = weather_tidy.reset_index()


weather_tidy


weather_tidy["date"] = pd.to_datetime(weather_tidy[["year", "month", "day"]]) # create new column 'date'


datetime_weather_tidy = weather_tidy.drop(columns = ["year", "month", "day"])


datetime_weather_tidy


datetime_weather_tidy = datetime_weather_tidy[["id", "date", "tmax", "tmin"]]


datetime_weather_tidy





billboard = pd.read_csv("billboard.csv")


billboard


billboard.columns.unique()


billboard[billboard.columns[-15:]].describe().T


billboard = billboard.rename(columns= {"date.entered": "date_entered"}) # rename column


billboard["date_entered"] = pd.to_datetime(billboard["date_entered"]) # convert column to type 'datetime'


data = ["year", "artist", "track", "time", "date_entered"]
billboard_tidy = billboard.melt(id_vars = data, var_name = "week", value_name = "place")


billboard_tidy


billboard_tidy = billboard_tidy.dropna() # remove NaN


billboard_tidy


billboard_tidy.place = billboard_tidy.place.astype(int)


billboard_tidy.dtypes


billboard_tidy.year.unique()


billboard_tidy.week = billboard_tidy.week.str.slice(2).astype(int)


billboard_tidy


billboard_tidy.dtypes


pd.Timedelta(7, "day") # or:  pd.Timedelta(1, "w")


intervals = billboard_tidy.week.apply(lambda x: pd.Timedelta(x - 1, "w"))


billboard_tidy["date"] = billboard_tidy["date_entered"] + intervals


billboard_tidy_clean = billboard_tidy


billboard_tidy_clean[billboard_tidy_clean.track == "Higher"]


billboard_tidy_clean = billboard_tidy_clean.drop(columns = ["date_entered", "week"])


billboard_tidy_clean = billboard_tidy_clean[["year", "artist", "track", "time", "date", "place"]]


billboard_tidy_clean
