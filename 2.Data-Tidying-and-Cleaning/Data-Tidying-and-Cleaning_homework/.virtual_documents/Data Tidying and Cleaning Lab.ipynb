%matplotlib inline


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import re











coffee_data = pd.read_csv("data/merged_data_cleaned.csv")


coffee_data


coffee_data.columns





coffee_data = coffee_data.drop(columns = ["Unnamed: 0"])





coffee_data.shape


coffee_data.info()


coffee_data.dtypes


# categorical features:
coffee_data.select_dtypes(include=["object"]).columns.tolist()


# numerical features:
coffee_data.select_dtypes(include=["number"]).columns.tolist()


coffee_data.describe().T





coffee_data.columns = coffee_data.columns.str.replace(".", "_")


coffee_data.columns = coffee_data.columns.str.lower()


coffee_data.columns.unique





coffee_data.bag_weight.unique()





def convert_to_kg(bag_weight):
    if "kg,lbs" in bag_weight:
        return int(bag_weight.replace("kg,lbs", ""))
    elif "kg" in bag_weight:
        return int(bag_weight.replace("kg", ""))
    elif "lbs" in bag_weight:
        return int(bag_weight.replace("lbs", "")) * 0.453592
    else:
        return int(bag_weight)


coffee_data.bag_weight = coffee_data.bag_weight.apply(convert_to_kg)


coffee_data.bag_weight = coffee_data.bag_weight.astype(int) # convert column type to float


coffee_data = coffee_data.rename(columns = {"bag_weight": "bag_weight_kg"}) # rename column name


coffee_data.bag_weight_kg.unique()


coffee_data.bag_weight_kg.dtype


len(coffee_data[coffee_data.bag_weight_kg > 2500]) 





fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 8))
ax1.boxplot(coffee_data.bag_weight_kg)
ax1.set_ylabel("kg")
ax2.hist(coffee_data.bag_weight_kg)
ax2.set_xlabel("kg")
ax2.set_ylabel("frequency")
fig.tight_layout()
plt.show()





coffee_data.harvest_year.unique()





def clean_harvest_years(harvest_year):
    if pd.isna(harvest_year):
        return np.nan

    coffee_data.loc[coffee_data.harvest_year == "4T/10", "harvest_year"] = "2010"
    coffee_data.loc[coffee_data.harvest_year == "08/09 crop", "harvest_year"] = "2008-2009"
    coffee_data.loc[coffee_data.harvest_year == "TEST", "harvest_year"] = np.nan
    coffee_data.loc[coffee_data.harvest_year == "mmm", "harvest_year"] = np.nan

    pattern_year = re.compile(r"(2\d{3})(?:\s*[-\/]\s*(2\d{2,3}))?")
    pattern_month = re.compile(r"([A-Z]{1}[a-z]{2}+)", re.IGNORECASE)
    
    match_full_year = pattern_year.search(harvest_year)
    match_month = pattern_month.search(harvest_year)
    
    if match_full_year:
        return match_full_year.group(0).replace(" ", "").replace("/", "-")
    else:
        return match_month.group(0).replace(" ", "").replace("/", "-")[0:3]


coffee_data.harvest_year = coffee_data.harvest_year.apply(clean_harvest_years)


coffee_data.harvest_year.unique()


coffee_data.grading_date


coffee_data.expiration





def remove_suffix(grading_date):
    suffs = ["st,", "nd,", "rd,", "th,"]
    for s in suffs:
        grading_date = grading_date.replace(s, "")
    return grading_date


coffee_data.grading_date = coffee_data.grading_date.apply(remove_suffix)
coffee_data.expiration = coffee_data.expiration.apply(remove_suffix)


coffee_data.grading_date = pd.to_datetime(coffee_data.grading_date, format = "mixed") 


coffee_data.expiration = pd.to_datetime(coffee_data.expiration, format = "mixed") 


coffee_data.grading_date


coffee_data.expiration


coffee_data.dtypes





coffee_data.country_of_origin.unique()


coffee_data.country_of_origin.value_counts(dropna = False)





coffee_data[coffee_data.country_of_origin.isna()]


coffee_data[coffee_data.ico_number == "3-37-1980"]


coffee_data[coffee_data.owner == "racafe & cia s.c.a"].head(5)


len(coffee_data[coffee_data.owner == "racafe & cia s.c.a"])





len(coffee_data[(coffee_data.owner == "racafe & cia s.c.a") & (coffee_data.country_of_origin == "Colombia")])


coffee_data.loc[coffee_data.country_of_origin.isna(), "country_of_origin"] = "Colombia" 


coffee_data[coffee_data.index == 1197]





coffee_data.owner


len(coffee_data.owner.unique())


len(coffee_data[coffee_data.owner.isna()])


coffee_data.owner_1


len(coffee_data.owner_1.unique())


len(coffee_data[coffee_data.owner_1.isna()])





coffee_data.owner_1.value_counts()


coffee_data["owner_1"].fillna("Juan Luis Alvarado Romero", inplace = True)





coffee_data = coffee_data.drop(columns=["owner"])


coffee_data = coffee_data.rename(columns= {"owner_1": "owner"})





coffee_data.producer


coffee_data.owner = coffee_data.owner.str.lower().str.strip()
coffee_data.producer = coffee_data.producer.str.lower().str.strip()


owner_producer = coffee_data[["owner", "producer"]]


owner_producer.head(5)


unique_owners_set = set(coffee_data.owner.unique())
unique_producers_set = set(coffee_data.producer.unique())

# new set with unique values that exists in both - unique_owners_set and unique_producers_set:
common_elements_set = unique_owners_set.intersection(unique_producers_set)

print(common_elements_set)
print(f"\nThere are {len(common_elements_set)} common elements between producer and owner.")





coffee_data.color.value_counts(dropna = False)


coffee_data.color.fillna(np.nan)





count_colors_country_df = coffee_data.groupby(["country_of_origin", "color"]).size().reset_index(name = "coffee_count")


count_colors_country_df.head(5)


pivot_count_colors_country = count_colors_country_df.pivot(
    index = "country_of_origin", 
    columns = "color", 
    values = "coffee_count", 
).reset_index()


pivot_count_colors_country





country_continent = {
    'Ethiopia': 'Africa',
    'Guatemala': 'North America',
    'Brazil': 'South America',
    'United States': 'North America',
    'United States (Hawaii)': 'North America',
    'Indonesia': 'Asia',
    'China': 'Asia',
    'Costa Rica': 'North America',
    'Mexico': 'North America',
    'Uganda': 'Africa',
    'Honduras': 'North America',
    'Taiwan': 'Asia',
    'Nicaragua': 'North America',
    'Tanzania, United Republic Of': 'Africa',
    'Kenya': 'Africa',
    'Thailand': 'Asia',
    'Colombia': 'South America',
    'Panama': 'North America',
    'Papua New Guinea': 'Australia',
    'El Salvador': 'North America',
    'Japan': 'Asia',
    'Ecuador': 'South America',
    'United States (Puerto Rico)': 'North America',
    'Haiti': 'North America',
    'Burundi': 'Africa',
    'Vietnam': 'Asia',
    'Philippines': 'Asia',
    'Rwanda': 'Africa',
    'Malawi': 'Africa',
    'Laos': 'Asia',
    'Zambia': 'Africa',
    'Myanmar': 'Asia',
    'Mauritius': 'Africa',
    'Cote d?Ivoire': 'Africa',
    'India': 'Asia'
}


coffee_data["continent"] = coffee_data["country_of_origin"].map(country_continent)


count_colors_continent = coffee_data.groupby(["continent", "color"]).size()


count_colors_continent_df = count_colors_continent.reset_index(name = "count_coffee")


count_colors_continent_df


pivot_count_colors_continent_df = coffee_data.groupby(["continent", "color"]).size().reset_index(name = "count_coffee")


pivot_count_colors_continent_df = count_colors_continent_df.pivot(
    index = "continent", 
    columns = "color", 
    values = "count_coffee",
).reset_index() 


pivot_count_colors_continent_df





coffee_ratings = ["aroma", "flavor", "aftertaste", "acidity", "body", "balance", "uniformity",
                  "clean_cup", "sweetness", "cupper_points", "total_cup_points", "moisture"]

fig, axs = plt.subplots(4, 3, figsize = (15, 20))
axs = axs.flatten()

for el in coffee_ratings:
    print(f"{coffee_data[el].name}: mean = {coffee_data[el].mean():.3f}, std = {coffee_data[el].std():.3f}, "
        f"max-min range = {coffee_data[el].max() - coffee_data[el].min()}")

    idx = coffee_ratings.index(el)
    axs[idx].hist(coffee_data[el], bins = 20, label = el)
    axs[idx].set_ylabel("frequency")
    axs[idx].legend()

plt.tight_layout()
plt.show()


coffee_data[coffee_ratings].describe().T


# 'total_cup_points' is cumulative score based on all coffee_ratings - sum of all other ratings values:
fig, axs = plt.subplots(1, 2, figsize = (10, 6))
axs[0].hist(coffee_data.total_cup_points, bins = 20, label = el)
axs[0].set_xlabel("total_cup_points rating")
axs[0].set_ylabel("frequency")

axs[1].boxplot(coffee_data.total_cup_points)
axs[1].set_ylabel("total_cup_points rating")

plt.tight_layout()
plt.show()





coffee_data[coffee_data.total_cup_points < 50]





row = coffee_data[coffee_data.index == 1310]


row[["aroma", "flavor", "aftertaste", "acidity", "body", "balance", "uniformity", "clean_cup", "sweetness", "cupper_points", "moisture"]]


coffee_data.loc[coffee_data.index == 1310, "aroma"] = coffee_data.aroma.mean()
coffee_data.loc[coffee_data.index == 1310, "flavor"] = coffee_data.flavor.mean()
coffee_data.loc[coffee_data.index == 1310, "aftertaste"] = coffee_data.aftertaste.mean()
coffee_data.loc[coffee_data.index == 1310, "acidity"] = coffee_data.acidity.mean()
coffee_data.loc[coffee_data.index == 1310, "body"] = coffee_data.body.mean()
coffee_data.loc[coffee_data.index == 1310, "balance"] = coffee_data.balance.mean()
coffee_data.loc[coffee_data.index == 1310, "uniformity"] = coffee_data.uniformity.mean()
coffee_data.loc[coffee_data.index == 1310, "clean_cup"] = coffee_data.clean_cup.mean()
coffee_data.loc[coffee_data.index == 1310, "sweetness"] = coffee_data.sweetness.mean()
coffee_data.loc[coffee_data.index == 1310, "cupper_points"] = coffee_data.cupper_points.mean()
coffee_data.loc[coffee_data.index == 1310, "total_cup_points"] = coffee_data.total_cup_points.mean()


row = coffee_data[coffee_data.index == 1310]


row[["aroma", "flavor", "aftertaste", "acidity", "body", "balance", "uniformity", "clean_cup", "sweetness", "cupper_points", "moisture", "total_cup_points"]]


fig, axs = plt.subplots(1, 2, figsize = (10, 6))
axs[0].hist(coffee_data.total_cup_points, bins = 20, label = el)
axs[0].set_xlabel("total cup points rating")
axs[0].set_ylabel("frequency")

axs[1].boxplot(coffee_data.total_cup_points)
axs[1].set_ylabel("total cup points rating")

plt.tight_layout()
plt.show()


# correlation matrix:

data = coffee_data[ratings_for_cor]
correlation_matrix = data.corr()

print(correlation_matrix)

plt.figure(figsize = (8, 8))
sns.heatmap(correlation_matrix, annot = True, cmap = "coolwarm", vmin = -1, vmax = 1)
plt.title("Correlation heatmap of coffee ratings")
plt.show()


correlation_matrix = coffee_data[["aroma", "flavor", "balance", "total_cup_points"]].corr()
print(correlation_matrix)

plt.figure(figsize=(6, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.show()





coffee_data.country_of_origin.unique()


coffee_data.region.unique()


country_region_company_altitude = coffee_data[["country_of_origin", "region", "company", "altitude_mean_meters"]]


country_region_company_altitude.head(15)


country_region_discrepancies = coffee_data[coffee_data.country_of_origin != coffee_data.region]


country_region_discrepancies[["country_of_origin", "region"]].head(10)


coffee_data.loc[coffee_data.region == "oromiya", "region"] = "oromia"


coffee_data.region = coffee_data.region.str.strip()


coffee_data.region.unique()


country_company_discrepancies = coffee_data[coffee_data.country_of_origin != coffee_data.company]


country_company_discrepancies[["country_of_origin", "company"]]


country_region = coffee_data.groupby(["country_of_origin", "region"]).size()


country_region = country_region.reset_index(name = "count_region")


country_region.sort_values(by=["country_of_origin", "count_region"], ascending=False)


coffee_data.altitude.unique()


coffee_data[["altitude", "altitude_low_meters", "altitude_high_meters", "altitude_mean_meters"]].head(20)





len(coffee_data.altitude.unique())


def convert_feet_to_meters(altitude):
    if isinstance(altitude, str):
        # regex to match 'ft', 'feet', 'f', 'ft.'
        match = re.search(r'\b(\d+(\.\d+)?)\s*(f(eet)?|ft\.?)\b', altitude, re.IGNORECASE)
        if match:
            feet_value = float(match.group(1))  
            meters_value = feet_value / 3.281 
            return f"{meters_value:.2f}"
    return altitude


coffee_data.altitude = coffee_data.altitude.apply(convert_feet_to_meters)


coffee_data.altitude.unique()


def remove_text(altitude):
    if isinstance(altitude, str):
        cleaned_altitude = re.sub(r"[a-zA-Z~\':+\s公尺(]+", "", altitude)
        return cleaned_altitude if cleaned_altitude else np.nan
    return altitude


coffee_data.altitude = coffee_data.altitude.apply(remove_text)


coffee_data.altitude.unique()


def remove_dots(altitude):
    if isinstance(altitude, str):
        cleaned_altitude = re.sub(r"\.\.{1,}", "", altitude)
        return cleaned_altitude
    return altitude


coffee_data.altitude = coffee_data.altitude.apply(remove_dots)


coffee_data.altitude.unique()


def separate_numbers(altitude):
    if isinstance(altitude, str) and len(altitude) >= 6:
        return re.sub(r"(\d{2})(00)(\d{2})", r"\1\2-\3", altitude)
    return altitude


coffee_data.altitude = coffee_data.altitude.apply(separate_numbers)


coffee_data.altitude.unique()








coffee_data.replace(["test", "TEST"], np.nan, inplace = True)


coffee_data.replace(["mmm", "MMM"], np.nan, inplace = True)


coffee_data.replace(["unknown", "UNKNOWN"], np.nan, inplace = True)





object_columns = coffee_data.select_dtypes(include=["object"]).columns

for col in object_columns:
    coffee_data[col] = coffee_data[col].astype("category")


coffee_data.columns





coffee_data = coffee_data[['species', 'country_of_origin', 'farm_name', 'lot_number',
       'mill','ico_number', 'company', 'altitude', 'unit_of_measurement', 'region', 
       'producer', 'owner', 'in_country_partner', 'harvest_year','grading_date',
       'number_of_bags', 'bag_weight_kg', 'variety', 'processing_method', 'aroma',
       'flavor', 'aftertaste', 'acidity', 'body', 'balance', 'uniformity', 'clean_cup',
       'sweetness', 'cupper_points', 'total_cup_points', 'moisture', 'category_one_defects',
       'quakers', 'color', 'category_two_defects', 'expiration', 'certification_body',
       'certification_address', 'certification_contact', 'altitude_low_meters', 
       'altitude_high_meters', 'altitude_mean_meters', 'continent']]


coffee_data


coffee_data.dtypes
